name: Build, Test, and Deploy (Vercel + Hetzner)

on:
  push:
    branches: [ dev, main-hetz, 'feat/**', 'fix/**' ]
  repository_dispatch:
    types: [ deploy ]
  workflow_dispatch:

env:
  VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
  NODE_VERSION: 22

permissions:
  contents: read
  actions: read
  packages: write

jobs:
  detect:
    runs-on: ubuntu-latest
    outputs:
      repository:       ${{ steps.p.outputs.repository }}
      repository_name:  ${{ steps.p.outputs.repository_name }}
      branch:           ${{ steps.p.outputs.branch }}
      project_type:     ${{ steps.detect.outputs.PROJECT_TYPE }}
      slug:             ${{ steps.cfg.outputs.SLUG }}
      port:             ${{ steps.cfg.outputs.PORT }}
      domain_prod:      ${{ steps.cfg.outputs.DOMAIN_PROD }}
      domain_admin:     ${{ steps.cfg.outputs.DOMAIN_ADMIN }}
    steps:
      - name: Extract payload (repo/branch)
        id: p
        run: |
          echo "repository=${{ github.event.client_payload.repository || github.repository }}" >> $GITHUB_OUTPUT
          echo "repository_name=${{ github.event.client_payload.repository_name || github.event.repository.name }}" >> $GITHUB_OUTPUT
          echo "branch=${{ github.event.client_payload.branch || github.ref_name }}" >> $GITHUB_OUTPUT

      - name: Checkout target website repo
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.p.outputs.repository }}
          ref: ${{ steps.p.outputs.branch }}
          fetch-depth: 0
          path: site

      - name: Verify package.json present
        working-directory: site
        run: test -f package.json || { echo "package.json not found in site/"; exit 1; }

      - name: Read .cicd-config.yml (slug/port/domains)
        id: cfg
        shell: bash
        working-directory: site
        run: |
          SLUG="site"
          PORT="3000"
          DOMAIN_PROD=""
          DOMAIN_ADMIN=""
          if [ -f ".cicd-config.yml" ]; then
            get_val(){ grep -E "^$1:" .cicd-config.yml | head -1 | awk -F': *' '{print $2}' | tr -d "\"'"; }
            SLUG=$(get_val slug || echo "$SLUG")
            PORT=$(get_val port || echo "$PORT")
            DOM_BLOCK="$(awk '/^domains:/{f=1;next} f && /^[^ ]/{f=0} f{print}' .cicd-config.yml)"
            DOMAIN_PROD="$(printf '%s\n' "$DOM_BLOCK" | awk '/prod:/{print $2}' | tr -d "\"'")"
            DOMAIN_ADMIN="$(printf '%s\n' "$DOM_BLOCK" | awk '/admin:/{print $2}' | tr -d "\"'")"
          fi
          echo "SLUG=$SLUG" >> $GITHUB_OUTPUT
          echo "PORT=$PORT" >> $GITHUB_OUTPUT
          echo "DOMAIN_PROD=$DOMAIN_PROD" >> $GITHUB_OUTPUT
          echo "DOMAIN_ADMIN=$DOMAIN_ADMIN" >> $GITHUB_OUTPUT

      - name: Detect project type
        id: detect
        working-directory: site
        run: |
          PT="node"
          if [ -f ".cicd-config.yml" ] && grep -qE '^project_type:\s*static' .cicd-config.yml; then
            PT="static"
          fi
          echo "PROJECT_TYPE=$PT" >> $GITHUB_OUTPUT

  build_test:
    runs-on: ubuntu-latest
    needs: [detect]
    steps:
      - uses: actions/checkout@v4
        with:
          repository: ${{ needs.detect.outputs.repository }}
          ref: ${{ needs.detect.outputs.branch }}
          path: site

      - name: Select Vercel IDs for this site
        run: |
          case "${{ needs.detect.outputs.repository_name }}" in
            drcodezenna)
              echo "VERCEL_ORG_ID=${{ secrets.DRCODEZENNA_VERCEL_ORG_ID }}" >> $GITHUB_ENV
              echo "VERCEL_PROJECT_ID=${{ secrets.DRCODEZENNA_VERCEL_PROJECT_ID }}" >> $GITHUB_ENV
              ;;
            *)
              echo "VERCEL_ORG_ID=" >> $GITHUB_ENV
              echo "VERCEL_PROJECT_ID=" >> $GITHUB_ENV
              ;;
          esac

      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install deps
        working-directory: site
        run: |
          if [ -f yarn.lock ]; then yarn install --immutable; \
          elif [ -f pnpm-lock.yaml ]; then corepack enable && pnpm i --frozen-lockfile; \
          else npm ci; fi

      - name: Lint (non-blocking)
        working-directory: site
        run: |
          if [ -f package.json ] && jq -e '.scripts.lint' package.json >/dev/null 2>&1; then \
            npm run lint || true; else echo "no lint script"; fi

      - name: Build
        working-directory: site
        run: npm run build

      - name: Unit tests (optional)
        working-directory: site
        run: npm test || echo "No tests / skipping"

      - name: (static only) assert out/
        if: needs.detect.outputs.project_type == 'static'
        working-directory: site
        run: test -d out || { echo "Static build missing out/"; exit 1; }

      - name: Upload out/ artifact (static only)
        if: needs.detect.outputs.project_type == 'static'
        uses: actions/upload-artifact@v4
        with:
          name: static-export
          path: site/out

  vercel_preview:
    needs: [detect, build_test]
    if: startsWith(needs.detect.outputs.branch, 'feat/') || startsWith(needs.detect.outputs.branch, 'fix/')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          repository: ${{ needs.detect.outputs.repository }}
          ref: ${{ needs.detect.outputs.branch }}
          path: site
      - name: Guard Vercel secrets
        id: guard
        run: |
          if [ -z "${{ env.VERCEL_TOKEN }}" ] || [ -z "${{ env.VERCEL_ORG_ID }}" ] || [ -z "${{ env.VERCEL_PROJECT_ID }}" ]; then
            echo "SKIP=1" >> $GITHUB_ENV
            echo "⚠️ Missing Vercel secrets; skipping Vercel preview."
          fi
      - if: env.SKIP != '1'
        working-directory: site
        run: npm i -g vercel
      - if: env.SKIP != '1'
        working-directory: site
        run: vercel pull --yes --environment=preview --token="${{ env.VERCEL_TOKEN }}" --scope="$VERCEL_ORG_ID"
      - if: env.SKIP != '1'
        working-directory: site
        run: vercel build --token="${{ env.VERCEL_TOKEN }}"
      - if: env.SKIP != '1'
        working-directory: site
        run: vercel deploy --prebuilt --token="${{ env.VERCEL_TOKEN }}"

  vercel_prod:
    needs: [detect, build_test]
    if: needs.detect.outputs.branch == 'dev'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          repository: ${{ needs.detect.outputs.repository }}
          ref: ${{ needs.detect.outputs.branch }}
          path: site
      - name: Guard Vercel secrets
        id: guard
        run: |
          if [ -z "${{ env.VERCEL_TOKEN }}" ] || [ -z "${{ env.VERCEL_ORG_ID }}" ] || [ -z "${{ env.VERCEL_PROJECT_ID }}" ]; then
            echo "SKIP=1" >> $GITHUB_ENV
            echo "⚠️ Missing Vercel secrets; skipping Vercel prod."
          fi
      - if: env.SKIP != '1'
        working-directory: site
        run: npm i -g vercel
      - if: env.SKIP != '1'
        working-directory: site
        run: vercel pull --yes --environment=production --token="${{ env.VERCEL_TOKEN }}" --scope="$VERCEL_ORG_ID"
      - if: env.SKIP != '1'
        working-directory: site
        run: vercel build --prod --token="${{ env.VERCEL_TOKEN }}"
      - if: env.SKIP != '1'
        working-directory: site
        run: vercel deploy --prebuilt --prod --token="${{ env.VERCEL_TOKEN }}"

  image_build_push:
    needs: [detect, build_test]
    if: needs.detect.outputs.project_type == 'node' && needs.detect.outputs.branch == 'main-hetz'
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.meta.outputs.image }}
      ref:   ${{ steps.meta.outputs.ref }}
    steps:
      - uses: actions/checkout@v4
        with:
          repository: ${{ needs.detect.outputs.repository }}
          ref: ${{ needs.detect.outputs.branch }}
          path: site

      - name: Derive image coordinates
        id: meta
        run: |
          OWNER_LOWER=$(echo "${{ github.repository_owner }}" | tr '[:upper:]' '[:lower:]')
          REPO_NAME="${{ needs.detect.outputs.repository_name }}"
          IMAGE="ghcr.io/${OWNER_LOWER}/${REPO_NAME}"
          SHORT="${GITHUB_SHA::7}"
          echo "image=$IMAGE" >> $GITHUB_OUTPUT
          echo "ref=$IMAGE:$SHORT" >> $GITHUB_OUTPUT

      - uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push site image (uses site's Dockerfile)
        uses: docker/build-push-action@v6
        with:
          context: site
          push: true
          tags: |
            ${{ steps.meta.outputs.ref }}
            ${{ steps.meta.outputs.image }}:latest

  hetzner_node:
    needs: [detect, image_build_push]
    if: needs.detect.outputs.project_type == 'node' && needs.detect.outputs.branch == 'main-hetz'
    runs-on: ubuntu-latest
    steps:
      - name: Compute SITE_ENV secret key for this repo
        id: k
        run: |
          KEY="$(echo '${{ needs.detect.outputs.repository_name }}' | tr '[:lower:]-' '[:upper:]_')"
          echo "SITE_ENV_KEY=SITE_ENV__${KEY}" >> $GITHUB_OUTPUT

      - name: Sanity check required SSH secrets
        run: |
          test -n "${{ secrets.HZ_HOST }}"    || { echo "❌ Missing secret: HZ_HOST"; exit 1; }
          test -n "${{ secrets.HZ_SSH_KEY }}" || { echo "❌ Missing secret: HZ_SSH_KEY"; exit 1; }

      - name: Deploy over SSH (Traefik + DB + app; bcrypt-safe env)
        uses: appleboy/ssh-action@v1
        env:
          SLUG:         ${{ needs.detect.outputs.slug }}
          PORT:         ${{ needs.detect.outputs.port }}
          DOMAIN:       ${{ needs.detect.outputs.domain_prod }}
          ADMIN_DOMAIN: ${{ needs.detect.outputs.domain_admin }}
          IMAGE_REF:    ${{ needs.image_build_push.outputs.ref }}
          SITE_ENV:     ${{ secrets[steps.k.outputs.SITE_ENV_KEY] }}
          GHCR_USER:    ${{ github.repository_owner }}
          GHCR_TOKEN:   ${{ secrets.GHCR_READ_TOKEN || secrets.GITHUB_TOKEN }}
          ACME_EMAIL:   ${{ secrets.TRAEFIK_ACME_EMAIL || 'admin@example.com' }}
        with:
          host: ${{ secrets.HZ_HOST }}
          username: ${{ secrets.HZ_USER || 'root' }}
          key: ${{ secrets.HZ_SSH_KEY }}
          port: 22
          timeout: 60s
          command_timeout: 25m
          envs: SLUG,PORT,DOMAIN,ADMIN_DOMAIN,IMAGE_REF,SITE_ENV,GHCR_USER,GHCR_TOKEN,ACME_EMAIL
          script: |
            set -eo pipefail

            SLUG="${SLUG:-}"; PORT="${PORT:-3000}"; DOMAIN="${DOMAIN:-}"; IMAGE_REF="${IMAGE_REF:-}"
            if [ -z "$SLUG" ] || [ -z "$DOMAIN" ] || [ -z "$IMAGE_REF" ]; then
              echo "Missing required input(s): SLUG='$SLUG' DOMAIN='$DOMAIN' IMAGE_REF='${IMAGE_REF:0:20}…'"
              exit 1
            fi
            echo "Deploying $SLUG → https://$DOMAIN  (image: ${IMAGE_REF:0:20}…)"

            # --- Networks ---
            docker network create proxy       >/dev/null 2>&1 || true
            docker network create core_db_net >/dev/null 2>&1 || true

            # --- Ensure Traefik reverse proxy is up (HTTP challenge) ---
            TDIR="/opt/services/traefik"
            mkdir -p "$TDIR/letsencrypt"
            [ -f "$TDIR/letsencrypt/acme.json" ] || install -m 600 /dev/null "$TDIR/letsencrypt/acme.json"
            cat > "$TDIR/docker-compose.yml" <<'YAML'
            services:
              traefik:
                image: traefik:v3.0
                restart: unless-stopped
                command:
                  - --providers.docker=true
                  - --providers.docker.exposedbydefault=false
                  - --entrypoints.web.address=:80
                  - --entrypoints.websecure.address=:443
                  - --certificatesresolvers.le.acme.httpchallenge=true
                  - --certificatesresolvers.le.acme.httpchallenge.entrypoint=web
                  - --certificatesresolvers.le.acme.email=${ACME_EMAIL}
                  - --certificatesresolvers.le.acme.storage=/letsencrypt/acme.json
                ports:
                  - 80:80
                  - 443:443
                volumes:
                  - /var/run/docker.sock:/var/run/docker.sock:ro
                  - ./letsencrypt:/letsencrypt
                networks: [proxy]
            networks:
              proxy:
                external: true
                name: proxy
            YAML
            (cd "$TDIR" && docker compose up -d)

            # --- GHCR login for pulls ---
            if [ -n "${GHCR_TOKEN:-}" ]; then
              echo "$GHCR_TOKEN" | docker login ghcr.io -u "$GHCR_USER" --password-stdin
            fi

            # --- Write app env (avoid $ expansion e.g. bcrypt) ---
            SITE_DIR="/opt/sites/${SLUG}"
            mkdir -p "$SITE_DIR"
            cd "$SITE_DIR"
            printf "%s\n" "${SITE_ENV:-}" | sed 's/\r$//' > app.env

            # Heads-up if DATABASE_URL points at localhost (bad inside container)
            if grep -qE '^DATABASE_URL=.*@localhost(:|/)' app.env; then
              echo "⚠️ DATABASE_URL points to localhost; inside container this won’t reach Postgres. Use host 'pgbouncer'."
            fi

            # --- Global DB stack (Postgres + PgBouncer) ---
            DB_DIR="/opt/services/postgres"
            mkdir -p "$DB_DIR"
            if grep -q '^POSTGRES_PASSWORD=' app.env; then
              awk -F= '/^POSTGRES_PASSWORD=/{print "POSTGRES_PASSWORD="$2}' app.env > "${DB_DIR}/.env"
            fi
            cat > "${DB_DIR}/docker-compose.yml" <<'DBYAML'
            services:
              postgres:
                image: postgres:15
                restart: always
                env_file: .env
                environment:
                  POSTGRES_USER: admin
                  POSTGRES_DB: drcode
                  POSTGRES_INITDB_ARGS: "--auth=scram-sha-256"
                volumes:
                  - pg_data:/var/lib/postgresql/data
                healthcheck:
                  test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
                  interval: 10s
                  timeout: 5s
                  retries: 10
                networks: [core_db_net]

              pgbouncer:
                image: edoburu/pgbouncer
                restart: always
                # .env provides POSTGRES_PASSWORD for Postgres. PgBouncer needs DB_PASSWORD explicitly:
                env_file: .env
                environment:
                  DB_USER: admin
                  DB_PASSWORD: ${POSTGRES_PASSWORD:-change_me_now}
                  DB_HOST: postgres
                  DB_NAME: drcode
                  POOL_MODE: transaction
                  MAX_CLIENT_CONN: 200
                  DEFAULT_POOL_SIZE: 20
                  AUTH_TYPE: plain
                depends_on:
                  postgres:
                    condition: service_healthy
                networks: [core_db_net]

            volumes:
              pg_data:

            networks:
              core_db_net:
                external: true
                name: core_db_net
            DBYAML

            (cd "${DB_DIR}" && docker compose up -d)
            # --- Sync admin password in case the volume existed already ---
            if grep -q '^POSTGRES_PASSWORD=' "${DB_DIR}/.env"; then
              . "${DB_DIR}/.env"  # brings POSTGRES_PASSWORD into this shell

              echo "Syncing Postgres 'admin' password to current POSTGRES_PASSWORD…"
              docker compose -f "${DB_DIR}/docker-compose.yml" exec -T postgres \
                sh -lc "PGPASSWORD='${POSTGRES_PASSWORD}' psql -U admin -d postgres -v ON_ERROR_STOP=1 \
                  -c \"ALTER ROLE admin WITH PASSWORD '${POSTGRES_PASSWORD}';\""
            fi

            # --- App stack behind Traefik ---
            cat > docker-compose.yml <<'APPLY'
            services:
              app:
                image: __IMAGE_REF__
                restart: unless-stopped
                env_file:
                  - app.env
                labels:
                  - traefik.enable=true
                  - traefik.http.routers.__SLUG__.rule=Host(`__DOMAIN__`)
                  - traefik.http.routers.__SLUG__.entrypoints=websecure
                  - traefik.http.routers.__SLUG__.tls.certresolver=le
                  - traefik.http.services.__SLUG__.loadbalancer.server.port=__PORT__
                networks: [proxy, core_db_net]
            networks:
              proxy:
                external: true
                name: proxy
              core_db_net:
                external: true
                name: core_db_net
            APPLY
            sed -i \
              -e "s|__IMAGE_REF__|${IMAGE_REF}|g" \
              -e "s|__SLUG__|${SLUG}|g" \
              -e "s|__DOMAIN__|${DOMAIN}|g" \
              -e "s|__PORT__|${PORT}|g" \
              docker-compose.yml

            # Add admin router labels if ADMIN_DOMAIN provided
            if [ -n "${ADMIN_DOMAIN:-}" ]; then
              awk -v s="${SLUG}" -v d="${ADMIN_DOMAIN}" '
                /- traefik\.http\.services\..*loadbalancer\.server\.port/ {
                  print;
                  print "                  - traefik.http.routers." s "-admin.rule=Host(`" d "`)";
                  print "                  - traefik.http.routers." s "-admin.entrypoints=websecure";
                  print "                  - traefik.http.routers." s "-admin.tls.certresolver=le";
                  print "                  - traefik.http.routers." s "-admin.service=" s;
                  next
                }
                {print}
              ' docker-compose.yml > docker-compose.tmp && mv docker-compose.tmp docker-compose.yml
            fi

            docker compose pull || true
            docker compose up -d --remove-orphans

            # Prisma migrations (best-effort)
            set +e
            docker compose exec -T app sh -lc "npx prisma migrate deploy" || true
            set -e

      - name: In-container health check (bypasses DNS/SSL)
        uses: appleboy/ssh-action@v1
        env:
          SLUG: ${{ needs.detect.outputs.slug }}
        with:
          host: ${{ secrets.HZ_HOST }}
          username: ${{ secrets.HZ_USER || 'root' }}
          key: ${{ secrets.HZ_SSH_KEY }}
          port: 22
          timeout: 60s
          command_timeout: 10m
          envs: SLUG
          script: |
            set -euo pipefail
            cd /opt/sites/${SLUG}
            PORT=$(docker compose exec -T app sh -lc 'printf "%s" "${PORT:-3000}"')
            echo "Detected PORT=$PORT"
            ok=0
            for path in /api/healthz /app/api/healthz; do
              echo "Probing http://127.0.0.1:${PORT}${path}"
              for i in $(seq 1 20); do
                if docker compose exec -T app node -e "require('http').get({host:'127.0.0.1',port:${PORT},path:'${path}'},r=>process.exit(r.statusCode===200?0:1)).on('error',()=>process.exit(1))"; then
                  echo "✅ ${path} OK"
                  ok=1
                  break
                fi
                echo "  retry $i"; sleep 3
              done
              [ $ok -eq 1 ] && break
            done
            if [ $ok -ne 1 ]; then
              echo "❌ App not healthy internally. Recent logs:" && docker compose logs --no-color --tail=200 app || true
              exit 1
            fi
            echo "✅ App healthy inside container"

      - name: Public health check (through Traefik/Cloudflare)
        run: |
          for i in {1..24}; do
            if curl -fsSL "https://${{ needs.detect.outputs.domain_prod }}/api/healthz" >/dev/null; then
              echo "✅ Public health OK"; exit 0; fi
            echo "retry $i"; sleep 5
          done
          echo "❌ Healthcheck failed"; exit 1

  hetzner_static:
    needs: [detect, build_test]
    if: needs.detect.outputs.project_type == 'static' && needs.detect.outputs.branch == 'main-hetz'
    runs-on: ubuntu-latest
    env:
      SLUG:   ${{ needs.detect.outputs.slug }}
      DOMAIN: ${{ needs.detect.outputs.domain_prod }}
    steps:
      - uses: actions/download-artifact@v4
        with:
          name: static-export
      - name: Move artifact to ./out
        run: |
          rm -rf out && mkdir -p out
          cp -R static-export/. out/

      # Mode A: SCP to nginx root if HETZNER_PATH is set
      - name: SCP upload to Hetzner (if HETZNER_PATH provided)
        if: env.HETZNER_PATH != ''
        env:
          SSH_KEY: ${{ secrets.HETZNER_SSH_KEY }}
        run: |
          echo "$SSH_KEY" > id_rsa && chmod 600 id_rsa
          mkdir -p ~/.ssh && ssh-keyscan -H "$HETZNER_HOST" >> ~/.ssh/known_hosts
          TARGET="${HETZNER_PATH%/}/${SLUG}"
          ssh -i id_rsa "$HETZNER_USER@$HETZNER_HOST" "sudo mkdir -p '$TARGET' && sudo chown -R $HETZNER_USER:$HETZNER_USER '$TARGET'"
          rsync -az --delete -e "ssh -i id_rsa" out/ "$HETZNER_USER@$HETZNER_HOST:$TARGET/"
          ssh -i id_rsa "$HETZNER_USER@$HETZNER_HOST" "sudo systemctl reload nginx || true"

      # Mode B: containerized nginx behind Traefik
      - name: Create Dockerfile for static image
        if: env.HETZNER_PATH == ''
        run: |
          cat > site.Dockerfile <<'DOCKER'
          FROM nginx:alpine
          COPY out/ /usr/share/nginx/html
          RUN adduser -D -g 'www' www \
           && chown -R www:www /usr/share/nginx/html \
           && sed -i 's/user  nginx;/user www;/' /etc/nginx/nginx.conf
          EXPOSE 80
          DOCKER

      - name: Set up Docker Buildx
        if: env.HETZNER_PATH == ''
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        if: env.HETZNER_PATH == ''
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & push static image
        if: env.HETZNER_PATH == ''
        uses: docker/build-push-action@v6
        with:
          context: .
          file: site.Dockerfile
          push: true
          tags: |
            ghcr.io/${{ github.repository_owner }}/static-${{ needs.detect.outputs.repository_name }}:${{ github.sha }}
            ghcr.io/${{ github.repository_owner }}/static-${{ needs.detect.outputs.repository_name }}:latest

      - name: Deploy static container on Hetzner
        if: env.HETZNER_PATH == ''
        uses: appleboy/ssh-action@v1
        env:
          SLUG: ${{ needs.detect.outputs.slug }}
          DOMAIN: ${{ needs.detect.outputs.domain_prod }}
          IMAGE_REF: ghcr.io/${{ github.repository_owner }}/static-${{ needs.detect.outputs.repository_name }}:${{ github.sha }}
          GHCR_USER: ${{ github.repository_owner }}
          GHCR_TOKEN: ${{ secrets.GHCR_READ_TOKEN || secrets.GITHUB_TOKEN }}
        with:
          host: ${{ secrets.HETZNER_HOST }}
          username: ${{ secrets.HETZNER_USER || 'root' }}
          key: ${{ secrets.HETZNER_SSH_KEY }}
          port: 22
          timeout: 60s
          command_timeout: 15m
          envs: SLUG,DOMAIN,IMAGE_REF,GHCR_USER,GHCR_TOKEN
          script: |
            set -euo pipefail
            docker network create proxy >/dev/null 2>&1 || true
            if [ -n "${GHCR_TOKEN:-}" ]; then
              echo "$GHCR_TOKEN" | docker login ghcr.io -u "$GHCR_USER" --password-stdin
            fi
            SITE_DIR="/opt/sites/${SLUG}"
            mkdir -p "$SITE_DIR"
            cd "$SITE_DIR"
            cat > docker-compose.yml <<YAML
            services:
              web:
                image: ${IMAGE_REF}
                restart: unless-stopped
                labels:
                  - traefik.enable=true
                  - traefik.http.routers.${SLUG}.rule=Host(\`${DOMAIN}\`)
                  - traefik.http.routers.${SLUG}.entrypoints=websecure
                  - traefik.http.routers.${SLUG}.tls.certresolver=le
                  - traefik.http.services.${SLUG}.loadbalancer.server.port=80
                networks: [proxy]
            networks:
              proxy:
                external: true
                name: proxy
            YAML
            docker compose pull || true
            docker compose up -d --remove-orphans

      - name: Static public check
        if: env.HETZNER_PATH == ''
        run: |
          for i in {1..24}; do
            if curl -fsSL "https://${{ needs.detect.outputs.domain_prod }}/" >/dev/null; then
              echo "✅ Site up"; exit 0; fi
            echo "retry $i"; sleep 5
          done
          echo "❌ Timed out"; exit 1
